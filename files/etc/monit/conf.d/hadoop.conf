# Port details available at
# http://kontext.tech/docs/DataAndBusinessIntelligence/p/default-ports-used-by-hadoop-services-hdfs-mapreduce-yarn

# Other ports are 9000.
check host namenode with address 127.0.0.1
  stop program = "/usr/local/bin/hadoopctl stop namenode"
  start program = "/usr/local/bin/hadoopctl start namenode"
  if failed
    port 9870
    retry 5
  then restart

# Other ports are 9866, 9867 and 41422.
check host datanode with address 127.0.0.1
  depends on namenode
  stop program = "/usr/local/bin/hadoopctl stop datanode"
  start program = "/usr/local/bin/hadoopctl start datanode"
  if failed
    port 9864
    retry 5
  then restart

# Other ports are 8030, 8031, 8033 and 8088
check host resourcemanager with address 127.0.0.1
  depends on namenode
  stop program = "/usr/local/bin/hadoopctl stop resourcemanager"
  start program = "/usr/local/bin/hadoopctl start resourcemanager"
  if failed
    port 8032
    retry 5
  then restart

# Other ports are 8040, 13562 and 44755.
check host nodemanager with address 127.0.0.1
  depends on resourcemanager
  stop program = "/usr/local/bin/hadoopctl stop nodemanager"
  start program = "/usr/local/bin/hadoopctl start nodemanager"
  if failed
    port 8042
    retry 5
  then restart

# Other ports are 10020 and 10033.
check host mapred with address 127.0.0.1
  depends on resourcemanager
  stop program = "/usr/local/bin/hadoopctl stop mapred"
  start program = "/usr/local/bin/hadoopctl start mapred"
  if failed
    port 19888
    retry 5
  then restart
